{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Лабораторна робота №7 ФІТ 4-6 Піць А.В.\n",
        "Завдання №1"
      ],
      "metadata": {
        "id": "FMPRdu3Z1Ydg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl_H_Sqi1M5m",
        "outputId": "0739938b-1619-46ac-87c8-060fde11b5d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m153.6/154.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.13.1)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357276 sha256=27816881aa626a58f857d639166bc10db6d466a41b707337ab6e397ed26aac45\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n",
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Y\n",
            "Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n",
            "('196', '242', 3.0, '881250949')\n",
            "('186', '302', 3.0, '891717742')\n",
            "('22', '377', 1.0, '878887116')\n",
            "('244', '51', 2.0, '880606923')\n",
            "('166', '346', 1.0, '886397596')\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "MAE:  0.7738\n",
            "MAE:  0.7364\n",
            "Найкращий алгоритм: SVD\n",
            "{'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.4}\n",
            "Рекомендовані фільми для користувача 196:\n",
            "Фільм 169, Оцінка 4.27\n",
            "Фільм 318, Оцінка 4.25\n",
            "Фільм 483, Оцінка 4.24\n",
            "Фільм 64, Оцінка 4.24\n",
            "Фільм 12, Оцінка 4.20\n",
            "Фільм 178, Оцінка 4.19\n",
            "Фільм 114, Оцінка 4.19\n",
            "Фільм 50, Оцінка 4.18\n",
            "Фільм 603, Оцінка 4.16\n",
            "Фільм 515, Оцінка 4.15\n"
          ]
        }
      ],
      "source": [
        "# Завантажуємо необхідні бібліотеки\n",
        "!pip install scikit-surprise\n",
        "\n",
        "from surprise import Dataset, KNNBasic, SVD\n",
        "from surprise.model_selection import cross_validate, GridSearchCV\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Завантаження датасету\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "\n",
        "# Виведення перших 5 рядків\n",
        "raw_ratings = data.raw_ratings[:5]\n",
        "for row in raw_ratings:\n",
        "    print(row)\n",
        "\n",
        "# Розбиваємо датасет на тренувальну і тестову вибірки\n",
        "trainset, testset = train_test_split(data, test_size=0.2)\n",
        "\n",
        "# Алгоритм 1: KNNBasic\n",
        "knn = KNNBasic()\n",
        "knn.fit(trainset)\n",
        "predictions_knn = knn.test(testset)\n",
        "mae_knn = accuracy.mae(predictions_knn)\n",
        "\n",
        "# Алгоритм 2: SVD\n",
        "svd = SVD()\n",
        "svd.fit(trainset)\n",
        "predictions_svd = svd.test(testset)\n",
        "mae_svd = accuracy.mae(predictions_svd)\n",
        "\n",
        "# Вибір найкращого алгоритму на основі MAE\n",
        "best_algo = 'SVD' if mae_svd < mae_knn else 'KNNBasic'\n",
        "print(f'Найкращий алгоритм: {best_algo}')\n",
        "\n",
        "# Крос-валідація для підбору параметрів для SVD\n",
        "param_grid = {'n_epochs': [20, 30], 'lr_all': [0.002, 0.005], 'reg_all': [0.4, 0.6]}\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
        "gs.fit(data)\n",
        "\n",
        "# Виведення найкращих параметрів\n",
        "print(gs.best_params['mae'])\n",
        "\n",
        "# Рекомендація для конкретного користувача\n",
        "algo = gs.best_estimator['mae']\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Виведення 10 фільмів для користувача з id 196\n",
        "user_id = '196'\n",
        "user_ratings = data.build_full_trainset().ur[trainset.to_inner_uid(user_id)]\n",
        "user_watched_movies = [trainset.to_raw_iid(iid) for (iid, _) in user_ratings]\n",
        "\n",
        "recommendations = []\n",
        "for iid in algo.trainset.all_items():\n",
        "    raw_iid = algo.trainset.to_raw_iid(iid)\n",
        "    if raw_iid not in user_watched_movies:\n",
        "        pred = algo.predict(user_id, raw_iid)\n",
        "        recommendations.append((raw_iid, pred.est))\n",
        "\n",
        "recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "print(\"Рекомендовані фільми для користувача 196:\")\n",
        "for movie_id, score in recommendations[:10]:\n",
        "    print(f\"Фільм {movie_id}, Оцінка {score:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновок:Ми завантажили датасет рецензій (ml-100k) за допомогою бібліотеки Surprise і провели аналіз перших 5 рядків для розуміння структури даних.\n",
        "Ми реалізували два алгоритми: KNNBasic і SVD, для рекомендаційної системи. Після навчання моделей на тренувальних даних і оцінки за допомогою тестових даних, було визначено, що алгоритм SVD має меншу похибку MAE.\n",
        "Після підбору параметрів за допомогою крос-валідації для алгоритму SVD, ми отримали найкращі параметри для моделі. Використовуючи ці параметри, було зроблено 10 рекомендацій для конкретного користувача."
      ],
      "metadata": {
        "id": "l8lQd1xp7YNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Завдання №2"
      ],
      "metadata": {
        "id": "YM1p9pZN7T1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Завантажуємо необхідні бібліотеки\n",
        "!pip install scikit-surprise\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "from surprise import Dataset, Reader, BaselineOnly\n",
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "# Завантаження датасету з інтернету\n",
        "if not os.path.exists('ml-100k'):\n",
        "    os.makedirs('ml-100k')\n",
        "\n",
        "url = 'https://files.grouplens.org/datasets/movielens/ml-100k/u.data'\n",
        "urllib.request.urlretrieve(url, 'ml-100k/u.data')\n",
        "\n",
        "# Вказуємо формат даних\n",
        "file_path = 'ml-100k/u.data'\n",
        "reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
        "data = Dataset.load_from_file(file_path, reader=reader)\n",
        "\n",
        "# Використання алгоритму Baseline для власної рекомендаційної системи\n",
        "bsl_options = {'method': 'als', 'n_epochs': 5, 'reg_u': 12, 'reg_i': 5}\n",
        "algo = BaselineOnly(bsl_options=bsl_options)\n",
        "\n",
        "# Крос-валідація для оцінки алгоритму\n",
        "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "\n",
        "# Отримання рекомендацій для конкретного користувача\n",
        "trainset = data.build_full_trainset()\n",
        "algo.fit(trainset)\n",
        "\n",
        "user_id = '196'  # Користувач, для якого отримаємо рекомендації\n",
        "user_ratings = trainset.ur[trainset.to_inner_uid(user_id)]\n",
        "user_watched_movies = [trainset.to_raw_iid(iid) for (iid, _) in user_ratings]\n",
        "\n",
        "recommendations = []\n",
        "for iid in algo.trainset.all_items():\n",
        "    raw_iid = algo.trainset.to_raw_iid(iid)\n",
        "    if raw_iid not in user_watched_movies:\n",
        "        pred = algo.predict(user_id, raw_iid)\n",
        "        recommendations.append((raw_iid, pred.est))\n",
        "\n",
        "recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "print(\"Рекомендовані фільми для користувача 196:\")\n",
        "for movie_id, score in recommendations[:10]:\n",
        "    print(f\"Фільм {movie_id}, Оцінка {score:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iag4c81y6i3Y",
        "outputId": "382fbffd-4fac-4ea3-ff4c-dfd6091e975a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.10/dist-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.13.1)\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.9391  0.9347  0.9400  0.9505  0.9426  0.9414  0.0052  \n",
            "MAE (testset)     0.7440  0.7397  0.7463  0.7521  0.7450  0.7454  0.0040  \n",
            "Fit time          0.19    0.22    0.22    0.34    0.23    0.24    0.05    \n",
            "Test time         0.09    0.09    0.24    0.11    0.09    0.12    0.06    \n",
            "Estimating biases using als...\n",
            "Рекомендовані фільми для користувача 196:\n",
            "Фільм 408, Оцінка 4.51\n",
            "Фільм 318, Оцінка 4.47\n",
            "Фільм 483, Оцінка 4.47\n",
            "Фільм 169, Оцінка 4.47\n",
            "Фільм 64, Оцінка 4.45\n",
            "Фільм 12, Оцінка 4.39\n",
            "Фільм 114, Оцінка 4.39\n",
            "Фільм 603, Оцінка 4.38\n",
            "Фільм 1449, Оцінка 4.35\n",
            "Фільм 178, Оцінка 4.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновок:Ми завантажили датасет ml-100k безпосередньо з інтернету, щоб забезпечити доступ до даних у середовищі Google Colab.\n",
        "Використовуючи алгоритм BaselineOnly, ми побудували власну рекомендаційну систему, яка оцінює фільми для користувачів на основі їхніх попередніх оцінок.\n",
        "За допомогою крос-валідації були оцінені результати роботи системи за метриками RMSE і MAE, і було згенеровано список рекомендованих фільмів для конкретного користувача."
      ],
      "metadata": {
        "id": "ChR0FiMg7KaF"
      }
    }
  ]
}